{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNGBHmy0jzf9Ox00CKHju8T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OVpvNhiY_3Ik"},"outputs":[],"source":["!pip install -q transformers datasets peft accelerate bitsandbytes"]},{"cell_type":"code","source":["import os\n","import warnings\n","warnings.filterwarnings('ignore')\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","import torch\n","print(f\"GPU: {torch.cuda.get_device_name(0)}\")"],"metadata":{"id":"KsG48WS3AN-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","import warnings\n","warnings.filterwarnings('ignore')\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n","from peft import LoraConfig, get_peft_model, TaskType\n","from datasets import Dataset\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"CdUyj0MEAUmF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_file_path = \"data\"\n","\n","with open(json_file_path, 'r', encoding='utf-8') as f:\n","    data = json.load(f)\n","\n","print(f\"üìä Loaded {len(data)} questions\")"],"metadata":{"id":"_TO83uxFArB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_conversation_new(item):\n","    question = item['cau_hoi']\n","    choices_text = \"\"\n","    for i, choice in enumerate(item['lua_chon']):\n","        choices_text += f\"{choice}\\n\"\n","    choices_text = choices_text.strip()\n","\n","    text = f\"\"\"<|im_start|>system\n","B·∫°n l√† m·ªôt chuy√™n gia v·ªÅ tr√≠ tu·ªá nh√¢n t·∫°o. B·∫°n s·∫Ω nh·∫≠n c√¢u h·ªèi tr·∫Øc nghi·ªám k√®m theo c√°c l·ª±a ch·ªçn, ch·ªçn ƒë√°p √°n ƒë√∫ng v√† gi·∫£i th√≠ch chi ti·∫øt.\n","<|im_start|>user\n","### C√¢u h·ªèi: {question}\n","### C√°c l·ª±a ch·ªçn:\n","{choices_text}\n","### C√¢u tr·∫£ l·ªùi:\n","<|im_start|>assistant\n","ƒê√°p √°n ƒë√∫ng l√†: {item['dap_an_dung']}\n","Gi·∫£i th√≠ch: {item['giai_thich']}\n","\"\"\".strip()\n","\n","    return text\n","\n","# Format t·∫•t c·∫£ conversations\n","conversations = [format_conversation_new(item) for item in data]\n","print(f\"‚úÖ Formatted {len(conversations)} conversations\")\n","print(conversations[0])\n","\n","\n","# Chia 85% train, 15% validation\n","train_conversations, val_conversations = train_test_split(\n","    conversations, test_size=0.15, random_state=42\n",")\n","\n","print(f\"üìÇ Train: {len(train_conversations)}, Validation: {len(val_conversations)}\")"],"metadata":{"id":"co6W45ZsArL-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_name = \"Qwen/Qwen3-1.7B\"\n","\n","try:\n","    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","    if tokenizer.pad_token is None:\n","        tokenizer.pad_token = tokenizer.eos_token\n","\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","        trust_remote_code=True\n","    )\n","    print(\"‚úÖ Model loaded successfully\")\n","except Exception as e:\n","    print(f\"‚ùå Error loading model: {e}\")\n","    print(\"üîÑ Try restarting kernel and running again\")"],"metadata":{"id":"CyUHeJycArOH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SimpleDataset(torch.utils.data.Dataset):\n","    def __init__(self, tokenized_data):\n","        self.data = tokenized_data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","train_dataset = SimpleDataset(train_tokenized)\n","val_dataset = SimpleDataset(val_tokenized)\n","print(f\"‚úÖ Dataset created with {len(train_dataset)} samples\")\n","print(f\"‚úÖ Dataset created with {len(val_dataset)} samples\")"],"metadata":{"id":"Q62vlwfUArQN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lora_config = LoraConfig(\n","    task_type=TaskType.CAUSAL_LM,\n","    inference_mode=False,\n","    r=8,\n","    lora_alpha=16,\n","    lora_dropout=0.1,\n","    target_modules=[\"q_proj\", \"v_proj\"]\n",")\n","\n","# In s·ªë l∆∞·ª£ng tham s·ªë tr∆∞·ªõc khi apply LoRA\n","def print_trainable_parameters(model):\n","    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    total = sum(p.numel() for p in model.parameters())\n","    print(f\"‚û°Ô∏è  Trainable parameters: {trainable} / {total} ({100 * trainable / total:.2f}%)\")\n","\n","print(\"üìå Tr∆∞·ªõc khi apply LoRA:\")\n","print_trainable_parameters(model)\n","\n","# Apply LoRA v√†o model\n","model = get_peft_model(model, lora_config)\n","\n","print(\"\\nüìå Sau khi apply LoRA:\")\n","print_trainable_parameters(model)"],"metadata":{"id":"0htVQIwYArSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=\"/kaggle/working/qwen_SICT\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=10,\n","    per_device_train_batch_size=1,\n","    gradient_accumulation_steps=4,\n","    save_steps=500,\n","    learning_rate=2e-4,\n","    weight_decay=0.01,\n","    logging_steps=10,\n","    fp16=True,\n","    remove_unused_columns=False,\n","    report_to=None\n",")"],"metadata":{"id":"3R3JwNCPArZu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def simple_collator(batch):\n","    input_ids = torch.stack([item['input_ids'] for item in batch])\n","    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n","    labels = torch.stack([item['labels'] for item in batch])\n","\n","    return {\n","        'input_ids': input_ids,\n","        'attention_mask': attention_mask,\n","        'labels': labels\n","    }\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=simple_collator,\n","    tokenizer=tokenizer,\n",")\n","\n","print(\"‚úÖ Trainer ready\")\n","\n","# CELL 10: Train\n","print(\"üöÄ Starting training...\")\n","try:\n","    trainer.train()\n","    trainer.save_model()\n","    tokenizer.save_pretrained(\"/kaggle/working/qwen_SICT\")\n","    print(\"üéâ Training completed!\")\n","except Exception as e:\n","    print(f\"‚ùå Training error: {e}\")\n","    print(\"üí° Try reducing batch_size or max_length further\")"],"metadata":{"id":"MOpqtO14ArcN"},"execution_count":null,"outputs":[]}]}